{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import svm\n",
    "import metrics as metric\n",
    "from warnings import filterwarnings\n",
    "import pdb\n",
    "import os \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(type_group=None, feature_set=None):\n",
    "    label_options = ['topic']\n",
    "    partition_info = pd.read_csv('/media/sven/New Volume/features/meta/processed_tasks/metadata/partition.csv')\n",
    "    for label in label_options:\n",
    "        if not os.path.exists('./data_csv/'+label):\n",
    "            os.makedirs('./data_csv/'+label)\n",
    "        train_lab, train_feat, devel_lab, devel_feat, test_lab, test_feat = [], [], [], [], [], []\n",
    "\n",
    "        feature_folder = '/media/sven/New Volume/features/c2_muse_topic/feature_segments/egemaps_aligned/'\n",
    "        label_folder = '/media/sven/New Volume/features/c2_muse_topic/label_segments/' + label + '/'\n",
    "\n",
    "        print('\\n ' + feature_set + ': ' + label)\n",
    "\n",
    "        print('\\n Preparing Partitions')\n",
    "        for index, row in partition_info.iterrows():\n",
    "            filename_id = str(row['Id']) + '.csv'\n",
    "            row_partition = row['Proposal']\n",
    "            label_df = pd.read_csv(label_folder + filename_id, index_col=None, dtype=np.float64)\n",
    "            feature_df = pd.read_csv(feature_folder + feature_set + '/' + filename_id, index_col=None, dtype=np.float64)\n",
    "            \n",
    "\n",
    "            feature_df = feature_df.groupby(['segment_id']).agg(type_group) \n",
    "            if row_partition == 'train':\n",
    "                train_feat.append(feature_df)\n",
    "                train_lab.append(label_df)\n",
    "            if row_partition == 'devel':\n",
    "                devel_feat.append(feature_df)\n",
    "                devel_lab.append(label_df)\n",
    "            if row_partition == 'test':\n",
    "                label_df['id'] = filename_id[:-4]\n",
    "                label_df['prediction_topic'] = 0  # dummy unused column, for prediction file\n",
    "                test_feat.append(feature_df)\n",
    "                test_lab.append(label_df)\n",
    "                    \n",
    "            \n",
    "        y_train = pd.concat(train_lab, axis=0).reset_index()\n",
    "        y_train = y_train['class_id']\n",
    "        x_train = pd.concat(train_feat, axis=0).reset_index().drop(columns='timestamp')\n",
    "\n",
    "        y_devel = pd.concat(devel_lab, axis=0).reset_index()\n",
    "        y_devel = y_devel['class_id']\n",
    "        x_devel = pd.concat(devel_feat, axis=0).reset_index().drop(columns='timestamp')\n",
    "\n",
    "        y_test = pd.concat(test_lab, axis=0).reset_index()\n",
    "        y_test = y_test[['id','segment_id','prediction_topic']]\n",
    "        x_test = pd.concat(test_feat, axis=0).reset_index().drop(columns='timestamp')\n",
    "            \n",
    "        train = pd.concat([x_train, y_train], axis=1)\n",
    "        devel = pd.concat([x_devel, y_devel], axis=1)\n",
    "        test = pd.concat ([x_test, y_test], axis=1)\n",
    "        \n",
    "\n",
    "        train.to_csv(os.path.join('./data_csv/',label,feature_set+'_train.csv'), index=False)\n",
    "        test.to_csv(os.path.join('./data_csv/',label,feature_set+'_test.csv'), index=False)\n",
    "        devel.to_csv(os.path.join('./data_csv/',label,feature_set+'_devel.csv'), index=False)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " vggface: topic\n",
      "\n",
      " Preparing Partitions\n"
     ]
    }
   ],
   "source": [
    "prepare_data('mean','vggface')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " vggface: arousal\n",
      "\n",
      " Preparing Partitions\n",
      "\n",
      " vggface: valence\n",
      "\n",
      " Preparing Partitions\n"
     ]
    }
   ],
   "source": [
    "for feature_set in ['vggface']:\n",
    "    num_feat = feat_conf[feature_set][0]\n",
    "    ind_off  = feat_conf[feature_set][1]\n",
    "    sep      = feat_conf[feature_set][2]\n",
    "    header   = feat_conf[feature_set][3]\n",
    "    prepare_data(None,feature_set) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import svm\n",
    "import metrics as metric\n",
    "from warnings import filterwarnings\n",
    "\n",
    "filterwarnings('ignore')\n",
    "\n",
    "print('\\n MuSe2020 Sub-Challenge MuSe-Topic (Emotion)')\n",
    "\n",
    "feature_set = 'egemaps'\n",
    "label_options = ['arousal', 'valence']\n",
    "partition_info = pd.read_csv('/media/sven/New Volume/features/meta/processed_tasks/metadata/partition.csv')\n",
    "classes = [0, 1, 2]\n",
    "\n",
    "complexities = [1e-5, 1e-4, 1e-3, 1e-2, 1e-1, 1e0]  # SVM complexities (linear kernel)\n",
    "\n",
    "feat_conf = {'egemaps': (88, 1, ',', 'infer'),\n",
    "             'deepspectrum': (4096, 1, ',', 'infer'),\n",
    "             'vggface': (512, 1, ',', 'infer'),\n",
    "             'fasttext': (300, 1, ',', 'infer'),\n",
    "             'xception': (2048, 1, ',', 'infer')}\n",
    "\n",
    "num_feat = feat_conf[feature_set][0]\n",
    "ind_off = feat_conf[feature_set][1]\n",
    "sep = feat_conf[feature_set][2]\n",
    "header = feat_conf[feature_set][3]\n",
    "\n",
    "for label in label_options:\n",
    "\n",
    "    train_lab, train_feat, devel_lab, devel_feat, test_lab, test_feat = [], [], [], [], [], []\n",
    "\n",
    "    feature_folder = '/media/sven/New Volume/features/c2_muse_topic/feature_segments/egemaps_aligned/'\n",
    "    label_folder = '/media/sven/New Volume/features/c2_muse_topic/label_segments/' + label + '/'\n",
    "\n",
    "    print('\\n ' + feature_set + ': ' + label)\n",
    "\n",
    "    print('\\n Preparing Partitions')\n",
    "    for index, row in partition_info.iterrows():\n",
    "        filename_id = str(row['Id']) + '.csv'\n",
    "        row_partition = row['Proposal']\n",
    "        label_df = pd.read_csv(label_folder + filename_id, index_col=None, sep=sep, header=header, dtype=np.float64)\n",
    "        feature_df = pd.read_csv(feature_folder + feature_set + '/' + filename_id, index_col=None, sep=sep,\n",
    "                                 header=header, usecols=range(ind_off, num_feat + ind_off), dtype=np.float64)\n",
    "        feature_df = feature_df.groupby(['segment_id']).agg('mean')\n",
    "        if row_partition == 'train':\n",
    "            train_feat.append(feature_df)\n",
    "            train_lab.append(label_df)\n",
    "        if row_partition == 'devel':\n",
    "            devel_feat.append(feature_df)\n",
    "            devel_lab.append(label_df)\n",
    "        if row_partition == 'test':\n",
    "            label_df['id'] = filename_id[:-4]\n",
    "            label_df['prediction_topic'] = 0  # dummy unused column, for prediction file\n",
    "            test_feat.append(feature_df)\n",
    "            test_lab.append(label_df)\n",
    "\n",
    "    y_train = pd.concat(train_lab, axis=0).reset_index()\n",
    "    y_train = y_train['class_id']\n",
    "    X_train = pd.concat(train_feat, axis=0).reset_index()\n",
    "\n",
    "    y_devel = pd.concat(devel_lab, axis=0).reset_index()\n",
    "    y_devel = y_devel['class_id']\n",
    "    X_devel = pd.concat(devel_feat, axis=0).reset_index()\n",
    "\n",
    "    y_test = pd.concat(test_lab, axis=0).reset_index()\n",
    "    y_test = y_test[['id', 'segment_id', 'prediction_topic']]\n",
    "    X_test = pd.concat(test_feat, axis=0).reset_index()\n",
    "\n",
    "    y_traindevel = np.concatenate((y_train, y_devel))\n",
    "    X_traindevel = np.concatenate((X_train, X_devel))\n",
    "\n",
    "    print('\\n Begin training SVM... (may take a while)')\n",
    "    uar_scores, fone_scores = [], []\n",
    "    for comp in complexities:\n",
    "        print('\\nComplexity {0:.6f}'.format(comp))\n",
    "        clf = svm.LinearSVC(C=comp, random_state=0)\n",
    "        clf.fit(X_train, y_train)\n",
    "        y_pred = clf.predict(X_devel)\n",
    "        uar_scores.append(metric.uar(y_devel, y_pred))\n",
    "        fone_scores.append(metric.f1(y_devel, y_pred))\n",
    "\n",
    "        print('UAR on Devel {0:.3f}'.format(uar_scores[-1]))\n",
    "        print('F1 on Devel {0:.3f}'.format(fone_scores[-1]))\n",
    "\n",
    "    optimum_complexity = complexities[np.argmax(uar_scores)]\n",
    "    uar = np.max(uar_scores)\n",
    "    f1 = np.max(fone_scores)\n",
    "\n",
    "    print('\\nOptimum complexity: {0:.6f}, maximum UAR: {1:.3f}, F1: {2:.3f}'.format(optimum_complexity, uar, f1))\n",
    "    print('Devel Combined Score: {0:.3f} '.format(metric.combined_task2(f1, uar)))\n",
    "\n",
    "    print('\\nCalculating Test Predictions')\n",
    "    clf = svm.LinearSVC(C=optimum_complexity, random_state=0)\n",
    "    clf.fit(X_traindevel, y_traindevel)\n",
    "    if label == 'arousal':\n",
    "        y_pred_arousal = clf.predict(X_test)\n",
    "    if label == 'valence':\n",
    "        y_pred_valence = clf.predict(X_test)\n",
    "\n",
    "pred_file_name = feature_set + '_test.csv'\n",
    "print('Writing file ' + pred_file_name + '\\n')\n",
    "prediction_df = pd.DataFrame(data={'id': y_test['id'],\n",
    "                                   'segment_id': y_test['segment_id'].astype(int),\n",
    "                                   'prediction_arousal': y_pred_arousal.astype(int),\n",
    "                                   'prediction_valence': y_pred_valence.astype(int),\n",
    "                                   'prediction_topic': y_test['prediction_topic'].astype(int), },\n",
    "                             columns=['id', 'segment_id', 'prediction_arousal', 'prediction_valence',\n",
    "                                      'prediction_topic'])\n",
    "prediction_df.to_csv(pred_file_name, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "length_seg = df.groupby(['segment_id'])['class_id'].count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('int64')"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "length_seg.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1.0: 18498,\n",
       " 2.0: 14188,\n",
       " 3.0: 16523,\n",
       " 4.0: 13537,\n",
       " 5.0: 13311,\n",
       " 6.0: 14729,\n",
       " 7.0: 14556,\n",
       " 8.0: 14150,\n",
       " 9.0: 12584,\n",
       " 10.0: 12312,\n",
       " 11.0: 12962,\n",
       " 12.0: 10229,\n",
       " 13.0: 10077,\n",
       " 14.0: 10711,\n",
       " 15.0: 10958,\n",
       " 16.0: 11434,\n",
       " 17.0: 8668,\n",
       " 18.0: 9263,\n",
       " 19.0: 9148,\n",
       " 20.0: 8074,\n",
       " 21.0: 7873,\n",
       " 22.0: 5939,\n",
       " 23.0: 6180,\n",
       " 24.0: 6622,\n",
       " 25.0: 8228,\n",
       " 26.0: 4897,\n",
       " 27.0: 4605,\n",
       " 28.0: 4496,\n",
       " 29.0: 5696,\n",
       " 30.0: 4713,\n",
       " 31.0: 4573,\n",
       " 32.0: 4192,\n",
       " 33.0: 3548,\n",
       " 34.0: 4361,\n",
       " 35.0: 2995,\n",
       " 36.0: 3250,\n",
       " 37.0: 1841,\n",
       " 38.0: 1348,\n",
       " 39.0: 1643,\n",
       " 40.0: 2044,\n",
       " 41.0: 817,\n",
       " 42.0: 326,\n",
       " 43.0: 514,\n",
       " 44.0: 89,\n",
       " 45.0: 353,\n",
       " 46.0: 18,\n",
       " 47.0: 89,\n",
       " 48.0: 5,\n",
       " 49.0: 11,\n",
       " 50.0: 180,\n",
       " 51.0: 148,\n",
       " 52.0: 10,\n",
       " 53.0: 27}"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "length_seg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
